{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Principal DF\n",
      "          mf1       mf2\n",
      "0   -4.260178 -3.266624\n",
      "1   -4.260178 -3.266624\n",
      "2    0.935873  1.056347\n",
      "3   -4.260178 -3.266624\n",
      "4   -4.260178 -3.266624\n",
      "..        ...       ...\n",
      "671 -3.320629 -0.407097\n",
      "672 -2.869474 -0.112426\n",
      "673 -3.040585 -1.770534\n",
      "674 -3.040585 -1.770534\n",
      "675 -3.040585 -1.770534\n",
      "\n",
      "[676 rows x 2 columns]\n",
      "\n",
      "Sklearn Principal DF\n",
      "          nf1       nf2\n",
      "0   -4.669071 -4.296014\n",
      "1   -4.669071 -4.296014\n",
      "2    1.062600  1.201243\n",
      "3   -4.669071 -4.296014\n",
      "4   -4.669071 -4.296014\n",
      "..        ...       ...\n",
      "671 -3.508132  0.221890\n",
      "672 -3.011817  0.070852\n",
      "673 -3.288800 -2.550508\n",
      "674 -3.288800 -2.550508\n",
      "675 -3.288800 -2.550508\n",
      "\n",
      "[676 rows x 2 columns]\n",
      "\n",
      "Sklearn U DF\n",
      "            0         1\n",
      "0   -4.669071 -4.296016\n",
      "1   -4.669071 -4.296016\n",
      "2    1.062600  1.201252\n",
      "3   -4.669071 -4.296016\n",
      "4   -4.669071 -4.296016\n",
      "..        ...       ...\n",
      "671 -3.508132  0.221995\n",
      "672 -3.011817  0.070855\n",
      "673 -3.288801 -2.550526\n",
      "674 -3.288801 -2.550526\n",
      "675 -3.288801 -2.550526\n",
      "\n",
      "[676 rows x 2 columns]\n",
      "\n",
      "Sklearn Sigma DF\n",
      "           0          1\n",
      "0  93.833313   0.000000\n",
      "1   0.000000  74.915517\n",
      "\n",
      "Sklearn V DF\n",
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.146929 -0.010275  0.173865  0.195203  0.071171  0.163453  0.186113   \n",
      "1 -0.178107  0.194147 -0.015424  0.097098 -0.156742 -0.133665  0.056472   \n",
      "\n",
      "         7         8         9   ...        72        73        74        75  \\\n",
      "0  0.103689  0.208173  0.194371  ...  0.090587  0.120228  0.098108  0.067321   \n",
      "1  0.185317  0.022471 -0.155589  ...  0.129964  0.137389  0.131745  0.066235   \n",
      "\n",
      "         76        77        78        79        80        81  \n",
      "0 -0.011909  0.055828  0.082026  0.078365  0.046369  0.032234  \n",
      "1  0.029922  0.105299  0.105068  0.146135  0.070393  0.067953  \n",
      "\n",
      "[2 rows x 82 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_matrix_to_dataframe(matrix, columns = []):\n",
    "    \"\"\" Converts a matrix into a dataframe with the given column labels. \"\"\"\n",
    "    return { label: list(col) for label, col in zip(columns, zip(*matrix)) }\n",
    "\n",
    "def convert_dataframe_to_matrix(df):\n",
    "    \"\"\" Converts a dataframe into a row matrix.\n",
    "\n",
    "    # Example Format:\n",
    "    sample_dataframe = convert_dataframe_to_matrix({\n",
    "        \"f1\": [1, 5, 1, 5, 8],\n",
    "        \"f2\": [2, 5, 4, 3, 1],\n",
    "        \"f3\": [3, 6, 2, 2, 2],\n",
    "        \"f4\": [4, 7, 3, 1, 2]\n",
    "    })\n",
    "    \n",
    "    print(sample_dataframe)\n",
    "    # Output:\n",
    "    [\n",
    "        [1, 2, 3, 4],\n",
    "        [5, 5, 6, 7],\n",
    "        [1, 4, 2, 3],\n",
    "        [5, 3, 2, 1],\n",
    "        [8, 1, 2, 2]\n",
    "    ]\n",
    "    \"\"\"\n",
    "    return [list(row) for row in zip(*df.values())]\n",
    "\n",
    "def parse_arff_to_dataframe(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    content = content.split(\"@data\")\n",
    "    attributes, data = content[0].split(\"@attribute\"), content[1].strip().split(\"\\n\")\n",
    "   \n",
    "    # Parse labels from the attribute tags, and keep track of numeric\n",
    "    # data types, which will be used for correcting data types of values later on\n",
    "    labels = [] \n",
    "    is_col_numeric = []\n",
    "    for col, attr in enumerate(attributes[1:]):\n",
    "        attr_parts = attr.replace(\"\\n\", \"\").strip().split(\" \")\n",
    "        labels.append(attr_parts[0])\n",
    "        \n",
    "        if attr_parts[1] == \"numeric\":\n",
    "            is_col_numeric.append(col)\n",
    "    \n",
    "    # Parse data rows\n",
    "    data_rows = []\n",
    "    for r in data:\n",
    "        row = []\n",
    "        for col, d in enumerate(r.split(\",\")):\n",
    "            fd = None \n",
    "            try:\n",
    "                # Integers for numeric columns else try to parse them as floats\n",
    "                fd = int(d) if col in is_col_numeric else float(d) \n",
    "            except ValueError:\n",
    "                # If an error occurs fallback to string value, if it is m then None\n",
    "                fd = d if d != \"m\" else None\n",
    "            row.append(fd)\n",
    "        \n",
    "        data_rows.append(row)\n",
    "    \n",
    "    # Just the relation tag for the arff\n",
    "    data_label = attributes[0].replace(\"@relation\", \"\").replace(\"\\n\", \"\").strip()\n",
    "    \n",
    "    # Reorganize parsed data to be stored column wise into a dict, with their key being\n",
    "    # their label\n",
    "    return data_label, { l: [d[i] for d in data_rows] for i, l in enumerate(labels) }\n",
    "\n",
    "def vector_magnitude(vector):\n",
    "    return sum(v ** 2 for v in vector) ** 0.5\n",
    "\n",
    "def identity(size):\n",
    "    return [[1.0 if i == j else 0.0 for j in range(size)] for i in range(size)]  \n",
    "\n",
    "def diagonal(matrix):\n",
    "    return [matrix[i][i] for i in range(len(matrix))]\n",
    "\n",
    "def transpose(matrix):\n",
    "    return [list(col) for col in zip(*matrix)]\n",
    "\n",
    "def subtract(matrix_a, matrix_b):\n",
    "    assert len(matrix_a) == len(matrix_b) and len(matrix_a[0]) == len(matrix_b[0]), \"Matrices not the same shape.\"\n",
    "    \n",
    "    return [[a - b for a, b in zip(row_a, row_b)] for row_a, row_b in zip(matrix_a, matrix_b)]\n",
    "\n",
    "def scale(matrix, val):\n",
    "    return [[item * val for item in row] for row in matrix]\n",
    "\n",
    "def dot(matrix_a, matrix_b):\n",
    "    assert len(matrix_a[0]) == len(matrix_b) or len(matrix_b[0]) == len(matrix_a), \"Dimensions of matrices are incompatible for dot product.\"\n",
    "    \n",
    "    # Swap the two matrices if incorrectly oriented\n",
    "    # A = m x j, B = j x n\n",
    "    if len(matrix_a[0]) != len(matrix_b):\n",
    "        matrix_a, matrix_b = matrix_b, matrix_a\n",
    "   \n",
    "    result = []\n",
    "    m, j, n = len(matrix_a), len(matrix_a[0]), len(matrix_b[0])\n",
    "    for row in range(m):\n",
    "        row_result = [sum(matrix_a[row][term] * matrix_b[term][col] for term in range(j)) for col in range(n)]\n",
    "        result.append(row_result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def determinant(matrix):\n",
    "    n = len(matrix)\n",
    "\n",
    "    # Base Case: Calculate the 2x2 matrix manually\n",
    "    if n == 2:\n",
    "        return matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n",
    "\n",
    "    det = 0\n",
    "    for cofactor_col in range(n):\n",
    "        # Calculate the submatrix by excluding the current row and column\n",
    "        submatrix = [[matrix[row][col] for col in range(n) if col != cofactor_col] for row in range(1, n)]\n",
    "        \n",
    "        # Calculate the determinant recursively\n",
    "        det += ((-1) ** cofactor_col) * matrix[0][cofactor_col] * determinant(submatrix)\n",
    "\n",
    "    return det\n",
    "\n",
    "# Standardize using standard normal distribution\n",
    "def snd_standardize_list(data):\n",
    "    assert type(data) == list and len(data) != 0, \"List must not be empty\"\n",
    "    \n",
    "    mean = sum(d for d in data) / len(data)\n",
    "    sample_std = (sum((mean - d) ** 2 for d in data) / (len(data) - 1)) ** 0.5\n",
    "    \n",
    "    return [(d - mean) / sample_std for d in data]\n",
    "\n",
    "# Calculates the covariance of two lists (population)\n",
    "def calculate_covariance(list_a, list_b):\n",
    "    assert type(list_a) == list and type(list_b) == list and len(list_a) == len(list_b), \"Lists must be of the same length\"\n",
    "\n",
    "    mean_a = sum(a for a in list_a) / len(list_a)\n",
    "    mean_b = sum(b for b in list_b) / len(list_b)\n",
    "\n",
    "    return sum((a - mean_a) * (b - mean_b) for a, b in zip(list_a, list_b)) / len(list_a)\n",
    "\n",
    "# Calculate eigenvalues and eigenvector values through Jacobi eigenvalue algorithm\n",
    "# https://en.wikipedia.org/wiki/Jacobi_eigenvalue_algorithm\n",
    "def jacobi_method_eigen(matrix, max_iterations = 5, tolerance = 1.0e-9, diff_tolerance = 1.0e-36):\n",
    "    def max_off_diag_elem(matrix):\n",
    "        row, col = 0, 1\n",
    "        max_elem = matrix[row][col]\n",
    "        n = len(matrix)\n",
    "\n",
    "        for r in range(n - 1):\n",
    "            for c in range(r + 1, n):\n",
    "                if abs(matrix[r][c]) >= max_elem:\n",
    "                    max_elem = abs(matrix[r][c])\n",
    "                    row, col = r, c\n",
    "        \n",
    "        return max_elem, row, col\n",
    "\n",
    "    def mutating_rotation(matrix, a, b, k, l, i, j):\n",
    "        m_kl = matrix[k][l]\n",
    "        m_ij = matrix[i][j]\n",
    "\n",
    "        matrix[k][l] = m_kl - a * (m_ij + b * m_kl)\n",
    "        matrix[i][j] = m_ij + a * (m_kl - b * m_ij)\n",
    "\n",
    "    n = len(matrix)\n",
    "    eigenvectors = identity(n)\n",
    "    for _ in range(max_iterations * (n ** 2)):\n",
    "        max_elem, max_elem_row, max_elem_col = max_off_diag_elem(matrix)\n",
    "    \n",
    "        if max_elem < tolerance:\n",
    "            return diagonal(matrix), eigenvectors\n",
    "        \n",
    "        diff = matrix[max_elem_col][max_elem_col] - matrix[max_elem_row][max_elem_row]\n",
    "        \n",
    "        if max_elem < abs(diff) * diff_tolerance:\n",
    "            t = max_elem / diff\n",
    "        else:\n",
    "            phi = diff / (2.0 * max_elem)\n",
    "            t = 1.0 / (abs(phi) + (phi ** 2 + 1.0) ** 0.5)\n",
    "            if phi < 0.0:\n",
    "                t = -t\n",
    "        \n",
    "        c = 1.0 / (t ** 2 + 1.0) ** 0.5\n",
    "        s = t * c\n",
    "        tau = s / (1.0 + c)\n",
    "\n",
    "        matrix[max_elem_row][max_elem_col] = 0.0\n",
    "        matrix[max_elem_row][max_elem_row] -= t * max_elem\n",
    "        matrix[max_elem_col][max_elem_col] += t * max_elem\n",
    "        \n",
    "        for i in range(max_elem_row): \n",
    "            mutating_rotation(matrix, s, tau, i, max_elem_row, i, max_elem_col)\n",
    "        for i in range(max_elem_row + 1, max_elem_col): \n",
    "            mutating_rotation(matrix, s, tau, max_elem_row, i, i, max_elem_col)\n",
    "        for i in range(max_elem_col + 1, n): \n",
    "            mutating_rotation(matrix, s, tau, max_elem_row, i, max_elem_col, i)\n",
    "        \n",
    "        for i in range(n):\n",
    "            mutating_rotation(eigenvectors, s, tau, i, max_elem_row, i, max_elem_col)\n",
    "    \n",
    "    raise RuntimeError(\"Jacobi wasn't able to converge the values\")\n",
    "\n",
    "def pca(data, n_components):\n",
    "    assert len(data[0]) >= n_components and n_components > 0, f\"Components must be between n and {len(data[0])}\"\n",
    "\n",
    "    data_t = transpose(data)\n",
    "    cov_matrix = [[calculate_covariance(feat_b, feat_a) for feat_b in data_t] for feat_a in data_t]\n",
    "    \n",
    "    # import numpy as np\n",
    "    # eig = np.linalg.eig(np.array(cov_matrix))\n",
    "    # eig = eig.eigenvectors.tolist()\n",
    "    # top_eigenvectors = transpose(eig)[:n_components]\n",
    "    \n",
    "    eigenvalues, eigenvectors = jacobi_method_eigen([[term for term in row] for row in cov_matrix], max_iterations=1000, tolerance=1.0e-128, diff_tolerance=1.0e-128)\n",
    "    sorted_eigen_pairs = sorted(zip(eigenvalues, transpose(eigenvectors)), key=lambda item : item[0], reverse=True) \n",
    "    top_eigenvectors = [vec for _, vec in sorted_eigen_pairs[:n_components]] \n",
    "   \n",
    "    return dot(data, transpose(top_eigenvectors))\n",
    "\n",
    "def svd(data):\n",
    "    # Transform data into square matrices by multiplying them by their transpositions\n",
    "    ata = dot(transpose(data), data)\n",
    "    aat = dot(data, transpose(data))\n",
    "\n",
    "    # Compute eigenvalues for both transposition multiplication combination\n",
    "    # Use numpy instead for faster calculations\n",
    "    # import numpy as np\n",
    "    # eig = np.linalg.eig(np.array(ata))\n",
    "    # singular_values = eig.eigenvalues.tolist()\n",
    "    # U = eig.eigenvectors.tolist()\n",
    "    \n",
    "    # eig = np.linalg.eig(np.array(aat))\n",
    "    # V = eig.eigenvectors.tolist()\n",
    "\n",
    "    # Waste your life by uncommenting the code below\n",
    "    eigenvalues, eigenvectors = jacobi_method_eigen(ata)\n",
    "    sorted_eigen_pairs = sorted(zip(eigenvalues, transpose(eigenvectors)), key=lambda item : item[0], reverse=True) \n",
    "    singular_values = [val ** 0.5 for val, _ in sorted_eigen_pairs] \n",
    "    U = [vec for _, vec in sorted_eigen_pairs] \n",
    "    \n",
    "    eigenvalues, eigenvectors = jacobi_method_eigen(aat)\n",
    "    sorted_eigen_pairs = sorted(zip(eigenvalues, transpose(eigenvectors)), key=lambda item : item[0], reverse=True) \n",
    "    V = [vec for _, vec in sorted_eigen_pairs] \n",
    "\n",
    "    Sigma = [[0.0] * len(data[0]) for _ in range(len(ata))]    # Diagonal matrix of singular values\n",
    "    for i in range(len(ata)):\n",
    "        Sigma[i][i] = singular_values[i]\n",
    "\n",
    "    return U, Sigma, V\n",
    "\n",
    "def parse_and_preprocess(file_path):\n",
    "    _, df = parse_arff_to_dataframe(file_path)\n",
    "    mat = convert_dataframe_to_matrix(df)\n",
    "    none_removed = [d for d in mat if None not in d] \n",
    "    feature_wise_mat = transpose(none_removed)[2:84]\n",
    "    standardized_mat = transpose([snd_standardize_list(data) for data in feature_wise_mat])\n",
    "    \n",
    "    return df, standardized_mat\n",
    "\n",
    "df1, mat1 = parse_and_preprocess(\"2017.arff\")\n",
    "df1, mat2 = parse_and_preprocess(\"2018.arff\")\n",
    "df1, mat3 = parse_and_preprocess(\"2019.arff\")\n",
    "df1, mat4 = parse_and_preprocess(\"2020.arff\")\n",
    "\n",
    "total_mat = mat1 + mat2 + mat3 + mat4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "# ===== MY CALCS ====== #\n",
    "n_components = 2\n",
    "result_pca = pca(total_mat, n_components=n_components)\n",
    "my_principal_df = pd.DataFrame(result_pca, columns=[\"mf\" + str(i + 1) for i in range(n_components)])\n",
    "print(\"My Principal DF\")\n",
    "print(my_principal_df)\n",
    "print()\n",
    "\n",
    "# Uncomment this if you want to waste your time\n",
    "# U, Sigma, V = svd(total_mat)\n",
    "# u_df = pd.DataFrame(U)\n",
    "# print(\"Sklearn U DF\")\n",
    "# print(u_df)\n",
    "# print()\n",
    "# sigma_df = pd.DataFrame(Sigma)\n",
    "# print(\"Sklearn Sigma DF\")\n",
    "# print(sigma_df)\n",
    "# print()\n",
    "# v_df = pd.DataFrame(V)\n",
    "# print(\"Sklearn V DF\")\n",
    "# print(v_df)\n",
    "# print()\n",
    "\n",
    "# ===== SKLEARN ===== #\n",
    "A = np.matrix(total_mat)\n",
    "df = pd.DataFrame(A)\n",
    "df_std = (df - df.mean()) / df.std()\n",
    "n_components = 2\n",
    "pca = PCA(n_components=n_components)\n",
    "principal_components = pca.fit_transform(df_std)\n",
    "principal_df = pd.DataFrame(data=principal_components, columns=[\"nf\" + str(i + 1) for i in range(n_components)])\n",
    "print(\"Sklearn Principal DF\")\n",
    "print(principal_df)\n",
    "print()\n",
    "\n",
    "svd = TruncatedSVD(n_components=n_components, n_iter=10, random_state=5)\n",
    "U = svd.fit_transform(df_std)\n",
    "Sigma = np.diag(svd.singular_values_)\n",
    "V = svd.components_\n",
    "\n",
    "u_df = pd.DataFrame(U)\n",
    "print(\"Sklearn U DF\")\n",
    "print(u_df)\n",
    "print()\n",
    "sigma_df = pd.DataFrame(Sigma)\n",
    "print(\"Sklearn Sigma DF\")\n",
    "print(sigma_df)\n",
    "print()\n",
    "v_df = pd.DataFrame(V)\n",
    "print(\"Sklearn V DF\")\n",
    "print(v_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Discussion\n",
    "\n",
    "**NOTE:** I have commented out my SVD calculations, since while it does converges to a result (~10 mins), the output buffer hangs for some reason.\n",
    "\n",
    "Looking at the results, my results deviates from the `sklearn` library on within about `±0.5` range. I believe this is brought about the eigenvalue, and eigenvectors calculations which in my case was implemented with the idea of approximating those values, and not actually getting their actual values. I used Jacobi's eigenvalue algorithm to approximate the eigenvalues, and eigenvectors of a given matrix, and comparing it to the results of `np.linalg.eig` in the `numpy` library, the results are about correct up to two decimal points. However, due to it being only accurate up to 2 decimal points that is enough reason to make the results of my calculations deviate from the `sklearn` library. Additionally, rounding errors, faulty programming, and not running enough iterations may also play a part in what caused the deviation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
